import static java.lang.System.err
import java.util.zip.*;

// variables need to be set from command line
Bin=""
SOFTWARE_CONFIG_FILE=""
ANNOTATION_CONFIG_FILE=""
MAPPING_FILE=""
COMPARISON_FILE=""
KEY_FILE=""
species=""
htseq_stranded=""
picard_strand_specificity=""
pre=""
r1adaptor=""
r2adaptor=""
flag_trim_read=false
flag_star=false
flag_star_1p=false
flag_tophat=false
flag_cufflinks=false
flag_htseq=false
flag_dexseq=false
flag_deseq=false
flag_no_replicates=false
flag_detectfusion=false
flag_fusion_chimerascan=false
flag_fusion_star=false
flag_fusion_mapsplice=false
flag_fusion_defuse=false
flag_fusion_fusioncatcher=false
flag_transcript=false
flag_kallisto=false
flag_rsem=false
flag_express=false
flag_lncrna=false
rsync_path=""

// user specific variables
uID=System.getProperty("user.name")
temp_dir="/scratch/$uID"

// variables to be set by pipeline
def SOFTWARE_PATH = [:]
def ANNOTATION_PATH
def sample_libs_run_path = [:]
def sample_internal_path = [:]
def sample_type_map = [:]
def sample_fusion_output = [:]
def star_crm_output = ""
def star_asm_output = ""
def tophat_crm_output = ""
def tophat_asm_output = ""

debug = {
  println "Bin=$Bin"
  println "SOFTWARE_CONFIG_FILE=$SOFTWARE_CONFIG_FILE"
  println "ANNOTATION_CONFIG_FILE=$ANNOTATION_CONFIG_FILE"
  println "MAPPING_FILE=$MAPPING_FILE"
  println "COMPARISON_FILE=$COMPARISON_FILE"
  println "KEY_FILE=$KEY_FILE"
  println "species=$species"
  println "htseq_stranded=$htseq_stranded"
  println "picard_strand_specificity=$picard_strand_specificity"
  println "pre=$pre"
  println "flag_trim_read=$flag_trim_read"
  println "r1adaptor=$r1adaptor"
  println "r2adaptor=$r2adaptor"
  println "flag_star=$flag_star"
  println "flag_star_1p=$flag_star_1p"
  println "flag_tophat=$flag_tophat"
  println "flag_cufflinks=$flag_cufflinks"
  println "flag_htseq=$flag_htseq"
  println "flag_dexseq=$flag_dexseq"
  println "flag_deseq=$flag_deseq"
  println "flag_no_replicates=$flag_no_replicates"
  println "flag_detectfusion=$flag_detectfusion"
  println "flag_fusion_chimerascan=$flag_fusion_chimerascan"
  println "flag_fusion_star=$flag_fusion_star"
  println "flag_fusion_mapsplice=$flag_fusion_mapsplice"
  println "flag_fusion_defuse=$flag_fusion_defuse"
  println "flag_fusion_fusioncatcher=$flag_fusion_fusioncatcher"
  println "flag_kallisto=$flag_kallisto"
  println "flag_rsem=$flag_rsem"
  println "flag_express=$flag_express"
  println "flag_lncrna=$flag_lncrna"
  fail "debug"
}

loadSoftwareConfig = {
  println "INFO: Loading software config file $SOFTWARE_CONFIG_FILE"
  File softwareConfigFile = new File(SOFTWARE_CONFIG_FILE)
  if(!softwareConfigFile.exists() || softwareConfigFile.isDirectory()) { 
    fail "ERROR: Could not open software config file $SOFTWARE_CONFIG_FILE"
  }
  softwareConfigFile.eachLine { line ->
    if(line.trim()) {
      def data = line.split("\\s+")
      def check_path = new File(data[1])
      if(!check_path.exists())
      {
        fail "ERROR: Path in software config file does not exist: " + data[1]
      }
      SOFTWARE_PATH[data[0]] = data[1]
    }
  }
}


loadAnnotationConfig = {
  println "INFO: Loading annotation config file $ANNOTATION_CONFIG_FILE"
  ANNOTATION_PATH = new ConfigSlurper(species).parse(new File(ANNOTATION_CONFIG_FILE).toURL())
  ANNOTATION_PATH.keySet().each{ ANNOTATION_PATH[it] = ANNOTATION_PATH[it].replaceAll("BIN_DIRECTORY_TOBE_SUBSTITUTE", Bin)}
  if(flag_lncrna)
  {
    ANNOTATION_PATH.GTF = ANNOTATION_PATH.GTF_LNCRNA
    ANNOTATION_PATH.starDB = ANNOTATION_PATH.starDB_LNCRNA
  }
  if(flag_trim_read)
  {
    ANNOTATION_PATH.starDB = ANNOTATION_PATH.starDB_adaptor
  }
  if(species == "hg19")
  {
    ANNOTATION_PATH.STAR_FUSION_GENOME_LIB = SOFTWARE_PATH.STAR_FUSION + "/Hg19_CTAT_resource_lib"
  }
}


parseMappingFile = {
	println "INFO: Parsing mapping file $MAPPING_FILE"
  File mappingFile = new File(MAPPING_FILE)
  if(!mappingFile.exists() || mappingFile.isDirectory()) { 
    fail "ERROR: Could not open mapping file $MAPPING_FILE"
  }
  check_unique = [:]                               // sometimes in the mapping file, the lib, sample, and run id isn't a unique identifier
	mappingFile.eachLine { line ->
		if(line.trim()) {
			data = line.split('\t')
			library_id = data[0]
      sample_name = data[1]
      run_id = data[2]
      fastq_path = data[3]
      sample_type = data[4]

      if(sample_name ==~ /^\d+.*/)
      {
        sample_name = "s_" + sample_name
      }
      key_value = sample_name + "\t" + library_id + "\t" + run_id
      
      if(check_unique[key_value])                                   //make sure the value in check_unique won't be groovy-false, such as 0
      {
        run_id += "_" + check_unique[key_value]
        check_unique[key_value] ++
      }
      else
      {
        check_unique[key_value] = 1
      }
      new_key_value = sample_name + "******" + library_id + "******" + run_id  // *,-,_ are the only characters that won't give weird stage name for next step, BPIPE bug?
      sample_libs_run_path[new_key_value] = fastq_path
      
      if(sample_type != "PE" && sample_type != "SE")
      {
        fail "ERROR: unrecognized sample type $sample_type for sample $sample_name"
      }
      if(sample_type_map[sample_name] && (sample_type_map[sample_name] != sample_type))
      {
        fail "ERROR: Sample $sample_name contains both PE and SE reads in mapping file"
      }
      else
      {
        sample_type_map[sample_name] = sample_type
      }

      internal_path = "intFiles/" + sample_name + "/" + library_id + "/" + run_id
      if(sample_internal_path.containsKey(sample_name))
  		{
    		sample_internal_path.get(sample_name).push(internal_path)
  		}
  		else
  		{
   			sample_internal_path.put(sample_name, [internal_path])
  		}
    }
	}	
}


linkRead = {
	branch.data = branch.name.split('\\*\\*\\*\\*\\*\\*')
	branch.sample = branch.data[0]
	branch.libid = branch.data[1]
	branch.runid = branch.data[2]
	output.dir = "intFiles/$branch.sample/$branch.libid/$branch.runid/"
	produce("link_read_" + branch.sample + ".done") {
	  exec "ln -s -f $input/* $output.dir >$output", "link_read"
  }
}


prepareRead = {
	branch.sample = branch.name
  branch.type = sample_type_map[branch.sample]
  branch.internal_path_list = inputs
  branch.R1 = []
  branch.R2 = []
  branch.min_read_len_cutadapt = -1
  branch.min_read_len_star = -1
  for(internal_path in branch.internal_path_list){
    from(glob(internal_path + "/*_R1_*.fastq.gz")){
      def R1_list = inputs.gz
      for(R1_file in R1_list){
        branch.R1.add(R1_file)
        if(branch.type == "PE")
        {
          def R1_file_name = R1_file.replaceFirst(~/^.*\/([^\/]+)$/, '$1')
          def R2_file_name = R1_file_name.replaceFirst(~/^(.*)R1(.*)$/, '$1R2$2')
          def R2_file = internal_path + "/" + R2_file_name
          File R2_FH = new File(R2_file)
          if(!R2_FH.exists() || R2_FH.isDirectory()) { 
            fail "ERROR: Could not find R2 file $R2_file"
          }
          branch.R2.add(R2_file)
        }
        if(branch.min_read_len_cutadapt == -1)  //check read lenth
        {
          def R1_input = new GZIPInputStream(new FileInputStream(R1_file))
          def R1_reader = new BufferedReader(new InputStreamReader(R1_input))
          def R1_line = R1_reader.readLine()
          R1_line = R1_reader.readLine() // get second line
          branch.min_read_len_cutadapt =  R1_line.size().intdiv(2)
          branch.min_read_len_star = branch.min_read_len_cutadapt - 1
        }
      }
    }
  }
	branch.R1_merge_list = branch.R1.join(" ")
	branch.R2_merge_list = (branch.type == "PE") ? branch.R2.join(" ") : ""
  branch.R1_alignment_read = branch.R1.join(",")
  branch.R2_alignment_read = (branch.type == "PE") ? branch.R2.join(",") : ""
  sample_fusion_output[branch.sample] = ""
}


mergeRead = {
	output.dir = "intFiles/$branch.sample/"
  if(branch.type == "SE") {
	  produce(branch.sample + "_R1_ORI.fastq"){	
		  exec "zcat $branch.R1_merge_list >$output.fastq", "merge_read"
    }
    branch.R1_fusion_read = output1.fastq
    branch.R2_fusion_read = ""
    branch.R1_transcript_read = output1.fastq
    branch.R2_transcript_read = ""
  }
  else if(branch.type == "PE"){
    produce(branch.sample + "_R1_ORI.fastq", branch.sample + "_R2_ORI.fastq"){ 
      exec "zcat $branch.R1_merge_list >$output1.fastq", "merge_read"
      exec "zcat $branch.R2_merge_list >$output2.fastq", "merge_read"
    }
    branch.R1_fusion_read = output1.fastq
    branch.R2_fusion_read = output2.fastq
    branch.R1_transcript_read = output1.fastq
    branch.R2_transcript_read = output2.fastq
  }
}

trimRead = {
    output.dir = "intFiles/$branch.sample/"
    if(branch.type == "SE") {
      produce(branch.sample + "_R1_CT.fastq"){ 
        exec "$SOFTWARE_PATH.PYTHON/python $SOFTWARE_PATH.CUTADAPT/cutadapt -f fastq -m $branch.min_read_len_cutadapt -a $r1adaptor -O 10 -o $output.fastq $input1.fastq >$output.dir/${branch.sample}_R1_CUTADAPT_STATS.txt 2>$output.dir/trim_read_se_${branch.sample}.blog", "trim_read" 
      }
    }
    else if(branch.type == "PE"){
      produce(branch.sample + "_R1_CT.fastq", branch.sample + "_R2_CT.fastq"){  
        exec "$SOFTWARE_PATH.PYTHON/python $SOFTWARE_PATH.CUTADAPT/cutadapt -f fastq -m $branch.min_read_len_cutadapt -a $r1adaptor -O 10 --paired-output $output.dir/${branch.sample}_R2_TEMP.fastq -o $output.dir/${branch.sample}_R1_TEMP.fastq $input1.fastq $input2.fastq >$output.dir/${branch.sample}_R1_CUTADAPT_STATS.txt 2>$output.dir/trim_read_pe1_${branch.sample}.blog", "trim_read" 
        
        exec "$SOFTWARE_PATH.PYTHON/python $SOFTWARE_PATH.CUTADAPT/cutadapt -f fastq -m $branch.min_read_len_cutadapt -a $r2adaptor -O 10 --paired-output $output1.fastq -o $output2.fastq $output.dir/${branch.sample}_R2_TEMP.fastq $output.dir/${branch.sample}_R1_TEMP.fastq >$output.dir/${branch.sample}_R2_CUTADAPT_STATS.txt 2>$output.dir/trim_read_pe2_${branch.sample}.blog", "trim_read"
      }
    }
}

compressRead = {
    output.dir = "intFiles/$branch.sample/"
    if(branch.type == "SE") {
	    produce(branch.sample + "_R1.fastq.gz"){
		    exec "gzip -c $input1.fastq >$output1.gz", "compress_read"
      }
      branch.R1_alignment_read = output1.gz
      branch.R1_transcript_read = output1.gz
    }
    else if(branch.type == "PE"){
      produce(branch.sample + "_R1.fastq.gz", branch.sample + "_R2.fastq.gz"){
        exec "gzip -c $input1.fastq >$output1.gz", "compress_read"
		    exec "gzip -c $input2.fastq >$output2.gz", "compress_read"
      }
      branch.R1_alignment_read = output1.gz
      branch.R2_alignment_read = output2.gz
      branch.R1_transcript_read = output1.gz
      branch.R2_transcript_read = output2.gz
	 }
}

runTopHat = {   // it doesn't matter if R2 list is empty
    output.dir = "intFiles/tophat2/$branch.sample/"
    produce("accepted_hits.bam"){
      exec "$SOFTWARE_PATH.TOPHAT/tophat2 -p 6 -r 70 --mate-std-dev 90 --GTF $ANNOTATION_PATH.GTF --transcriptome-index=$ANNOTATION_PATH.TRANS_INDEX -o $output.dir --rg-id ${branch.sample}_1 --rg-sample $branch.sample --rg-library ${branch.sample}_1 --rg-platform Illumina --rg-platform-unit ${branch.sample}_1 $ANNOTATION_PATH.BOWTIE2_INDEX $branch.R1_alignment_read $branch.R2_alignment_read >$output.dir/tophat2_${branch.sample}.blog 2>&1", "run_tophat"
    }
}

reorderSam = {
    output.dir = "gene/alignments/tophat2/"
    produce(pre + "_" + branch.sample + ".bam"){
      exec "$SOFTWARE_PATH.JAVA/java -Xms256m -Xmx10g -XX:-UseGCOverheadLimit -Djava.io.tmpdir=$temp_dir -jar $SOFTWARE_PATH.PICARD/picard.jar ReorderSam I=$input.bam O=$output.bam REFERENCE=$ANNOTATION_PATH.REF_SEQ VALIDATION_STRINGENCY=LENIENT TMP_DIR=$temp_dir CREATE_INDEX=true >${output.dir}/tophat_reordersam_${branch.sample}.blog 2>&1", "reorder_sam"
    }
}

runStar1P = {   // it doesn't matter if R2 list is empty
    output.dir = "intFiles/$branch.sample/"
    produce(branch.sample + "_STAR_1PASS_Aligned.out.sam", branch.sample + "_STAR_1PASS_SJ.out.tab"){
    	exec "$SOFTWARE_PATH.STAR/STAR --genomeDir $ANNOTATION_PATH.starDB --readFilesIn $branch.R1_alignment_read $branch.R2_alignment_read --runThreadN 12 --outFileNamePrefix $output.dir/${branch.sample}_STAR_1PASS_ --outSAMstrandField intronMotif --outFilterIntronMotifs RemoveNoncanonicalUnannotated --outSAMattributes All --outSAMunmapped Within --readFilesCommand zcat >$output.dir/star1p_${branch.sample}.blog 2>&1", "run_star_1p"
    }
}

runStar2PGG = {
    output.dir = "intFiles/$branch.sample/star2passGG"
    produce("SAindex"){
    	exec "$SOFTWARE_PATH.STAR/STAR --runMode genomeGenerate --outFileNamePrefix $output.dir/ --genomeDir $output.dir --genomeFastaFiles $ANNOTATION_PATH.REF_SEQ --sjdbFileChrStartEnd $input.tab --sjdbOverhang $branch.min_read_len_star --runThreadN 12 >$output.dir/star2pgg_${branch.sample}.blog 2>&1", "run_star_2p_gg"
    }
    branch.star_2p_gg = output.dir
}

runStar2P = {   // it doesn't matter if R2 list is empty
    output.dir = "intFiles/$branch.sample"
    produce(branch.sample + "_STAR_2PASS_Aligned.out.sam", branch.sample + "_STAR_2PASS_SJ.out.tab"){
    	exec "$SOFTWARE_PATH.STAR/STAR --genomeDir $branch.star_2p_gg --readFilesIn $branch.R1_alignment_read $branch.R2_alignment_read --runThreadN 12 --outFileNamePrefix $output.dir/${branch.sample}_STAR_2PASS_ --outSAMstrandField intronMotif --outFilterIntronMotifs RemoveNoncanonicalUnannotated --outSAMattributes All --outSAMunmapped Within --readFilesCommand zcat >$output.dir/star2p_${branch.sample}.blog 2>&1", "run_star_2p"
    }
}

runStarProcessing = {
    output.dir = "intFiles/$branch.sample"
    produce(input.sam.replaceFirst(~/^.*\/([^\/]+)$/, '$1') + "_filtered.sam"){
    	exec "$SOFTWARE_PATH.PERL/perl $Bin/starProcessing.pl $input.sam >$output.dir/star_processing_${branch.sample}.blog 2>&1", "run_star_processing"
    }
}

addGroup = {
    output.dir = "gene/alignments"
    produce(pre + "_" + branch.sample + ".bam"){
      exec "$SOFTWARE_PATH.JAVA/java -Xms256m -Xmx10g -XX:-UseGCOverheadLimit -Djava.io.tmpdir=$temp_dir -jar $SOFTWARE_PATH.PICARD/picard.jar AddOrReplaceReadGroups I=$input.sam O=$output.bam SORT_ORDER=coordinate VALIDATION_STRINGENCY=LENIENT TMP_DIR=$temp_dir CREATE_INDEX=true RGID=${branch.sample}_1 RGLB=_1 RGPL=Illumina RGPU=${branch.sample}_1 RGSM=$branch.sample >${output.dir}/star_addreadgroup_${branch.sample}.blog 2>&1", "add_group"
    }
}


runCufflinks = {
    if(current_aligner == "star"){
      output.dir = "cufflinks/$branch.sample"
    }
    else if(current_aligner == "tophat"){
      output.dir = "cufflinks/tophat2/$branch.sample"
    }
    else
    {
      fail "ERROR: unrecognized aligner parameter"
    }
    produce("transcripts.gtf"){
    	exec "$SOFTWARE_PATH.CUFFLINKS/cufflinks -q -p 12 --no-update-check -N -G $ANNOTATION_PATH.GTF -o $output.dir $input.bam >$output.dir/cufflinks_${current_aligner}_${branch.sample}.blog 2>&1", "run_cufflinks"
    }
}


sortSamQueryName = {
    if(current_aligner == "star"){
      output.dir = "intFiles/$branch.sample"
    }
    else if(current_aligner == "tophat"){
      output.dir = "intFiles/tophat2/$branch.sample"
    }
    else
    {
      fail "ERROR: unrecognized aligner parameter"
    }
    produce(branch.sample + "_queryname_sorted.sam"){
    	exec "$SOFTWARE_PATH.JAVA/java -Xms256m -Xmx48g -XX:-UseGCOverheadLimit -Djava.io.tmpdir=$temp_dir -jar $SOFTWARE_PATH.PICARD/picard.jar MergeSamFiles INPUT=$input OUTPUT=$output.sam SORT_ORDER=queryname TMP_DIR=$temp_dir VALIDATION_STRINGENCY=LENIENT >$output.dir/sort_sam_queryname_${current_aligner}_${branch.sample}.blog 2>&1", "sort_sam_query_name"
    }
}


runHtseq = {
    if(current_aligner == "star"){
      output.dir = "gene/counts_gene/"
    }
    else if(current_aligner == "tophat"){
      output.dir = "gene/counts_gene/tophat2"
    }
    else
    {
      fail "ERROR: unrecognized aligner parameter"
    }
    produce(branch.sample + ".htseq_count"){
    	exec "$SOFTWARE_PATH.PYTHON/python $SOFTWARE_PATH.HTSEQ/htseq-count -m intersection-strict -s $htseq_stranded -t exon $input.sam $ANNOTATION_PATH.GTF >$output.htseq_count 2>$output.dir/htseq_${current_aligner}_${branch.sample}.blog", "run_htseq"
    }
}

runDexseq = {
    if(current_aligner == "star"){
      output.dir = "exon/counts_exon/"
    }
    else if(current_aligner == "tophat"){
      output.dir = "exon/counts_exon/tophat2"
    }
    else
    {
      fail "ERROR: unrecognized aligner parameter"
    }
    produce(branch.sample + ".dexseq_count"){
    	exec "$SOFTWARE_PATH.PYTHON/python $SOFTWARE_PATH.DEXSEQ/dexseq_count.py -s no $ANNOTATION_PATH.DEXSEQ_GTF $input.sam $output.dexseq_count >$output.dir/dexseq_${current_aligner}_${branch.sample}.blog 2>&1", "run_dexseq"
    }
}


collectRNAseqMetrics = {
    def chart_dir = output.dir
    if(current_aligner == "star"){
      output.dir = "metrics/crm"
      chart_dir = output.dir
      output.dir = "intFiles"
    }
    else if(current_aligner == "tophat"){
      output.dir = "metrics/tophat2/crm"
      chart_dir = output.dir
      output.dir = "intFiles/tophat2"
    }
    else
    {
      fail "ERROR: unrecognized aligner parameter"
    }
    produce(pre + "_" + branch.sample + "_CollectRnaSeqMetrics.txt"){
    	exec "$SOFTWARE_PATH.JAVA/java -Xms256m -Xmx3g -XX:-UseGCOverheadLimit -Djava.io.tmpdir=$temp_dir -jar $SOFTWARE_PATH.PICARD/picard.jar CollectRnaSeqMetrics I=$input.bam O=$output.txt CHART_OUTPUT=${chart_dir}/${pre}_${branch.sample}_CollectRnaSeqMetrics_chart.pdf REF_FLAT=$ANNOTATION_PATH.REF_FLAT RIBOSOMAL_INTERVALS=$ANNOTATION_PATH.RIBOSOMAL_INTERVALS STRAND_SPECIFICITY=$picard_strand_specificity METRIC_ACCUMULATION_LEVEL=null METRIC_ACCUMULATION_LEVEL=SAMPLE >$output.dir/rnaseq_metrics_${current_aligner}_${branch.sample}.blog 2>&1", "collect_rnaseq_metrics"
    }
    if(current_aligner == "star"){
      star_crm_output += " -metrics $output.txt"
    }
    else if(current_aligner == "tophat"){
      tophat_crm_output += " -metrics $output.txt"
    }
}

collectAlignmentSummaryMetrics = {
    if(current_aligner == "star"){
      output.dir = "intFiles"
    }
    else if(current_aligner == "tophat"){
      output.dir = "intFiles/tophat2"
    }
    else
    {
      fail "ERROR: unrecognized aligner parameter"
    }
    produce(pre + "_" + branch.sample + "_AlignmentSummaryMetrics.txt"){
    	exec "$SOFTWARE_PATH.JAVA/java -Djava.io.tmpdir=$temp_dir -jar $SOFTWARE_PATH.PICARD/picard.jar CollectAlignmentSummaryMetrics INPUT=$input.bam OUTPUT=$output.txt REFERENCE_SEQUENCE=$ANNOTATION_PATH.REF_SEQ METRIC_ACCUMULATION_LEVEL=null METRIC_ACCUMULATION_LEVEL=SAMPLE VALIDATION_STRINGENCY=LENIENT >$output.dir/alignment_summary_metrics_${current_aligner}_${branch.sample}.blog 2>&1", "collect_alignment_summary_metrics"
    }

    if(current_aligner == "star"){
      star_asm_output += " -metrics $output.txt"
    }
    else if(current_aligner == "tophat"){
      tophat_asm_output += " -metrics $output.txt"
    }
}

runChimeraScan = {    // chimerascan does not support single end read
    output.dir = "fusion/chimerascan/$branch.sample"
    if(branch.type == "PE")
    {
      produce("chimeras.bedpe")
      {
        exec "rm -rf ${output.dir}/*", "run_remove_partial_file"

        exec "$SOFTWARE_PATH.PYTHON/python $SOFTWARE_PATH.CHIMERASCAN/chimerascan_run.py --bowtie-path=$SOFTWARE_PATH.BOWTIE -p 6 --quals solexa --multihits=10 --filter-false-pos=$Bin/data/hg19_bodymap_false_positive_chimeras.txt $ANNOTATION_PATH.CHIMERASCAN_INDEX $branch.R1_fusion_read $branch.R2_fusion_read $output.dir >$output.dir/chimerascan_${branch.sample}.blog 2>&1", "run_chimerascan"
      }
      sample_fusion_output[branch.sample] += " --chimerascan $output.bedpe"
    }
}

runStarFusion = {   // it doesn't matter if R2 list is empty
    output.dir = "fusion/star_fusion/$branch.sample"
    def read_para = "--left_fq $branch.R1_fusion_read"
    if(branch.type == "PE")
    {
      read_para += " --right_fq $branch.R2_fusion_read"
    }
    produce("star-fusion.fusion_candidates.final.abridged")
    {
      exec "rm -rf ${output.dir}/*", "run_remove_partial_file"

      exec "$SOFTWARE_PATH.PERL/perl $SOFTWARE_PATH.STAR_FUSION/STAR-Fusion --genome_lib_dir $ANNOTATION_PATH.STAR_FUSION_GENOME_LIB $read_para --output_dir $output.dir >$output.dir/star_fusion_${branch.sample}.blog 2>&1", "run_star_fusion"
    }
    sample_fusion_output[branch.sample] += " --star $output.abridged"
}

runMapSplice = {
    output.dir = "fusion/mapsplice/$branch.sample"
    def read_para = "-1 $branch.R1_fusion_read"
    if(branch.type == "PE")
    {
      read_para += " -2 $branch.R2_fusion_read"
    }
    produce("fusions_well_annotated.txt")
    {
      exec "rm -rf ${output.dir}/*", "run_remove_partial_file"

      exec "$SOFTWARE_PATH.PYTHON/python $SOFTWARE_PATH.MAPSPLICE/mapsplice.py -p 6 --bam --fusion-non-canonical -c $ANNOTATION_PATH.chrSplits -x $ANNOTATION_PATH.BOWTIE_INDEX -o $output.dir $read_para --gene-gtf $ANNOTATION_PATH.GTF >$output.dir/mapsplice_${branch.sample}.blog 2>&1", "run_mapsplice"
    }
    sample_fusion_output[branch.sample] += " --mapsplice $output.txt"
}

runDefuse = {
    output.dir = "fusion/defuse/$branch.sample"
    if(branch.type == "PE")
    {
      produce("results.filtered.tsv")
      {
        exec "rm -rf ${output.dir}/*", "run_remove_partial_file"

        exec "$SOFTWARE_PATH.PERL/perl $SOFTWARE_PATH.DEFUSE/scripts/defuse.pl --config $SOFTWARE_PATH.DEFUSE/scripts/config_homo_sapiens.txt --output $output.dir --parallel 12 --1fastq ${branch.R1_fusion_read} --2fastq ${branch.R2_fusion_read} >$output.dir/defuse_${branch.sample}.blog 2>&1", "run_defuse"
      }
      sample_fusion_output[branch.sample] += " --defuse $output.tsv"
    }
}

runFusionCatcher = {
    output.dir = "fusion/fusioncatcher/$branch.sample"
    if(branch.type == "PE")
    {
      produce("final-list_candidate-fusion-genes.txt")
      {
        exec "rm -rf ${output.dir}/*", "run_remove_partial_file"

        exec "$SOFTWARE_PATH.FUSIONCATCHER/bin/fusioncatcher -d $SOFTWARE_PATH.FUSIONCATCHER/data/ensembl_v77d -i ${branch.R1_fusion_read},${branch.R2_fusion_read} -o $output.dir -p 6 --skip-update-check --config=$SOFTWARE_PATH.FUSIONCATCHER/bin/configuration.cfg >$output.dir/fusioncatcher_${branch.sample}.blog 2>&1", "run_fusioncatcher"
      }
      sample_fusion_output[branch.sample] += " --fusioncatcher $output.txt"
    }
}

mergeFusion = {
  output.dir = "fusion"
  branch.merge_fusion = sample_fusion_output[branch.sample]
  produce(pre + "_merged_fusions_" + branch.sample + ".txt"){
    exec "$Bin/MergeFusion $branch.merge_fusion --out $output.txt --normalize_gene $Bin/data/hugo_data_073013.tsv", "merge_fusion"
  }
}

runBowtie2 = {
  output.dir = "intFiles/bowtie2/$branch.sample/"
  def read_para = ""
  if(branch.type == "PE")
  {
    read_para = "-1 $branch.R1_transcript_read -2 $branch.R2_transcript_read"
  }
  else
  {
      read_para = "-U $branch.R1_transcript_read"
  }
  produce(branch.sample + "_bowtie2.sam"){
  exec "$SOFTWARE_PATH.BOWTIE2/bowtie2 --all --maxins 600 --rdg 6,5 --rfg 6,5 --score-min L,-.6,-.4 --no-discordant --no-mixed --threads 24 -x $ANNOTATION_PATH.TRANS_INDEX_DEDUP $read_para -S $output.sam >$output.dir/bowtie2_${branch.sample}.blog 2>&1", "run_bowtie2"
  branch.bowtie2_sam = output.sam
  }
}

runExpress = {
  output.dir = "transcript/counts/express/$branch.sample"
  produce("results.xprs") {
    exec "$SOFTWARE_PATH.EXPRESS/express --output-dir $output.dir --no-update-check $ANNOTATION_PATH.TRANS_FASTA_DEDUP $branch.bowtie2_sam >$output.dir/express_${branch.sample}.blog 2>&1", "run_express"
  }
}


runKallisto = {
  output.dir = "transcript/counts/kallisto/$branch.sample"
  def read_para = ""
  if(branch.type == "PE")
  {
    read_para = "$branch.R1_transcript_read $branch.R2_transcript_read"
  }
  else
  {
    read_para = "--single -l 250 $branch.R1_transcript_read"
  }
  produce("abundance.txt") {
    exec "$SOFTWARE_PATH.KALLISTO/kallisto quant -i $ANNOTATION_PATH.KALLISTO_INDEX -o $output.dir -b 100 $read_para >$output.dir/kallisto_${branch.sample}.blog 2>&1", "run_kallisto"
  }
}

runRsem = {
  output.dir = "transcript/counts/rsem/$branch.sample"
  def read_para = ""
  if(branch.type == "PE")
  {
    read_para = "--paired-end $branch.R1_transcript_read $branch.R2_transcript_read"
  }
  else
  {
    read_para = "$branch.R1_transcript_read"
  }
  if(flag_trim_read)
  {
    read_para += " --gzipped-read-file"
  }
  produce(branch.sample + "_RSEM.transcript.bam", branch.sample + "_RSEM.genome.bam", branch.sample + "_RSEM.isoforms.results", branch.sample + "_RSEM.genes.results") {
    exec "$SOFTWARE_PATH.RSEM/rsem-calculate-expression -p 8 --star --star-path $SOFTWARE_PATH.STAR --estimate-rspd --append-names --output-genome-bam $read_para $ANNOTATION_PATH.RSEM_DB $output1.bam.prefix.prefix >$output.dir/rsem_${branch.sample}.blog 2>&1", "run_rsem"
  }
}

runRsemPlot = {
  output.dir = "metrics/RSEM"
  produce(pre + "_" + branch.sample + "_RSEM.pdf") {
    exec "$SOFTWARE_PATH.RSEM/rsem-plot-model $input1.bam.prefix.prefix $output.pdf >$output.dir/rsem_plot_${branch.sample}.blog 2>&1", "run_rsem_plot"
  }
}


countMatrixHtseq = {
  if(current_aligner == "star"){
    output.dir = "gene/counts_gene/"
  }
  else if(current_aligner == "tophat"){
    output.dir = "gene/counts_gene/tophat2"
  }
  else
  {
    fail "ERROR: unrecognized aligner parameter"
  }
  produce(pre + "_htseq_all_samples.txt") {
    exec "$SOFTWARE_PATH.PYTHON/python $Bin/rnaseq_count_matrix.py $output.dir .htseq_count $output.txt $ANNOTATION_PATH.geneNameConversion >$output.dir/count_matrix_htseq_${current_aligner}.blog 2>&1", "count_matrix_htseq"
  }
}


countMatrixDexseq = {
  if(current_aligner == "star"){
    output.dir = "exon/counts_exon/"
  }
  else if(current_aligner == "tophat"){
    output.dir = "exon/counts_exon/tophat2"
  }
  else
  {
    fail "ERROR: unrecognized aligner parameter"
  }
  produce(pre + "_dexseq_all_samples.txt") {
    exec "$SOFTWARE_PATH.PYTHON/python $Bin/rnaseq_count_matrix.py $output.dir .dexseq_count $output.txt $ANNOTATION_PATH.geneNameConversion >$output.dir/count_matrix_dexseq_${current_aligner}.blog 2>&1", "count_matrix_dexseq"
  }
} 


countMatrixKallisto = {
  output.dir = "transcript/counts/kallisto/"
  produce(pre + "_kallisto_all_genes.txt") {
    exec "$SOFTWARE_PATH.PYTHON/python $Bin/mergeKallistoAbundance.py $output.dir abundance.txt $output.txt >$output.dir/count_matrix_kallisto.blog 2>&1", "count_matrix_kallisto"
  }
}


countMatrixRsem = {
  output.dir = "transcript/counts/rsem/"
  produce(pre + "_rsem_all_genes.txt") {
    exec "$SOFTWARE_PATH.PYTHON/python $Bin/mergeRSEMcounts.py $output.dir isoforms.results $output.txt >$output.dir/count_matrix_rsem.blog 2>&1", "count_matrix_rsem"
  }
}


mergeAlignmentSummary = {
  if(current_aligner == "star"){
    branch.asm_output = star_asm_output
    output.dir = "metrics"
  }
  else if(current_aligner == "tophat"){
    branch.asm_output = tophat_asm_output
    output.dir = "metrics/tophat2"
  }
  else
  {
    fail "ERROR: unrecognized aligner parameter"
  }
  produce(pre + "_AlignmentSummaryMetrics.txt") {
    exec "$SOFTWARE_PATH.PERL/perl $Bin/mergePicardMetrics.pl $branch.asm_output >$output.txt 2>$output.dir/merge_alignment_summary_${current_aligner}.blog", "merge_alignment_summary"
  } 

}


mergeRNAseqMetrics = {
  if(current_aligner == "star"){
    branch.crm_output = star_crm_output
    output.dir = "metrics"
  }
  else if(current_aligner == "tophat"){
    branch.crm_output = tophat_crm_output
    output.dir = "metrics/tophat2"
  }
  else
  {
    fail "ERROR: unrecognized aligner parameter"
  }
  produce(pre + "_CollectRnaSeqMetrics.txt") {
    exec "$SOFTWARE_PATH.PERL/perl $Bin/mergePicardMetrics.pl $branch.crm_output >$output.txt 2>$output.dir/merge_rnaseq_metrics_${current_aligner}.blog", "merge_rnaseq_metrics"
  }
}


mergeCutadaptMetrics = {
  def root_dir = output.dir
  output.dir = "metrics"
  produce(pre + "_CutAdaptStats.txt") {
    exec "$SOFTWARE_PATH.PYTHON/python $Bin/mergeCutAdaptStats.py $root_dir/intFiles/ '*CUTADAPT_STATS.txt' $output.txt >$output.dir/merge_cutadapt_metrics.blog 2>&1", "merge_cutadapt_metrics"
  }
}


runDeseqStar = {
  output.dir = "gene"
  def root_dir = output.dir
  output.dir = "gene/gsa"
  output.dir = "gene/differentialExpression_gene"
  output.dir = "gene/clustering"
  produce("MDS_plot.pdf", "counts_DESeqscaled_clust.pdf"){
  def extra_para = "";
  if(flag_deseq)
  {
    extra_para += "-pre $pre -diff_out $root_dir/differentialExpression_gene -count_out $root_dir/counts_gene -gsa_out $root_dir/gsa -species $species -samplekey $KEY_FILE -comparisons $COMPARISON_FILE"
    if(flag_aligner == "star" && flag_no_replicates)
    {
      extra_para += " -no_replicates"
    }
  }
  else
  {
    extra_para += " -clusterOnly"
  }
  exec "$SOFTWARE_PATH.PERL/perl $Bin/run_DESeq_wrapper.pl -cluster_out $output.dir -config $SOFTWARE_CONFIG_FILE -bin $Bin -counts $root_dir/counts_gene/${pre}_htseq_all_samples.txt $extra_para >$output.dir/deseq_star.blog 2>&1", "run_deseq_star"
  }
}

runDeseqTophat = {
  output.dir = "gene"
  def root_dir = output.dir
  output.dir = "gene/gsa/tophat2"
  output.dir = "gene/differentialExpression_gene/tophat2"
  output.dir = "gene/clustering/tophat2"
  produce("MDS_plot.pdf", "counts_DESeqscaled_clust.pdf"){
  def extra_para = "";
  if(flag_deseq)
  {
    extra_para += "-pre $pre -diff_out $root_dir/differentialExpression_gene/tophat2 -count_out $root_dir/counts_gene/tophat2 -gsa_out $root_dir/gsa/tophat2 -species $species -samplekey $KEY_FILE -comparisons $COMPARISON_FILE"
    if(flag_aligner == "star" && flag_no_replicates)
    {
      extra_para += " -no_replicates"
    }
  }
  else
  {
    extra_para += " -clusterOnly"
  }
  exec "$SOFTWARE_PATH.PERL/perl $Bin/run_DESeq_wrapper.pl -cluster_out $output.dir -config $SOFTWARE_CONFIG_FILE -bin $Bin -counts $root_dir/counts_gene/tophat2/${pre}_htseq_all_samples.txt $extra_para >$output.dir/deseq_tophat.blog 2>&1", "run_deseq_tophat"
  }
}

runDeseqKallisto = {
  output.dir = "transcript"
  def root_dir = output.dir
  output.dir = "transcript/differentialExpression_trans/kallisto"
  output.dir = "transcript/counts/kallisto"
  output.dir = "transcript/clustering/kallisto"
  produce("MDS_plot.pdf", "counts_DESeqscaled_clust.pdf"){
  def extra_para = "";
  if(flag_deseq)
  {
    extra_para = "-pre $pre -diff_out $root_dir/differentialExpression_trans/kallisto -species $species -counts $root_dir/counts/kallisto/${pre}_kallisto_all_genes.txt -samplekey $KEY_FILE -comparisons $COMPARISON_FILE"
  }
  else
  {
    extra_para = "-counts $root_dir/counts/kallisto/${pre}_merged_kallisto_counts.txt -clusterOnly"
  }
  exec "$SOFTWARE_PATH.PERL/perl $Bin/run_DESeq_wrapper.pl -count_out $root_dir/counts/kallisto -cluster_out $root_dir/clustering/kallisto -config $SOFTWARE_CONFIG_FILE -bin $Bin $extra_para >$output.dir/deseq_kallisto.blog 2>&1", "run_deseq_kallisto"
  }
}


runDeseqRsem = {
  output.dir = "transcript"
  def root_dir = output.dir
  output.dir = "transcript/differentialExpression_trans/rsem"
  output.dir = "transcript/counts/rsem"
  output.dir = "transcript/clustering/rsem"
  produce("MDS_plot.pdf", "counts_DESeqscaled_clust.pdf"){
  def extra_para = "";
  if(flag_deseq)
  {
    extra_para = "-pre $pre -diff_out $root_dir/differentialExpression_trans/rsem -species $species -counts $root_dir/counts/rsem/${pre}_rsem_all_genes.txt -samplekey $KEY_FILE -comparisons $COMPARISON_FILE"
  }
  else
  {
    extra_para = " -counts $root_dir/counts/rsem/${pre}_merged_rsem_counts.txt -clusterOnly"
  }
  exec "$SOFTWARE_PATH.PERL/perl $Bin/run_DESeq_wrapper.pl -count_out $root_dir/counts/rsem -cluster_out $root_dir/clustering/rsem -config $SOFTWARE_CONFIG_FILE -bin $Bin $extra_para >$output.dir/deseq_rsem.blog 2>&1", "run_deseq_rsem"
  }
}


runCleanup = {
  def root_dir = output.dir
  output.dir = "progress"
  produce("done.txt")
  {
    exec "find $root_dir -name \"*.blog\" -type f ! -path \"$root_dir/progress/*\" -exec mv --backup=numbered {} $output.dir \\; >$output.txt", "run_cleanup"
  }
}


runRsync = {
  if(rsync_path)
  {
    exec "rsync --exclude \"intFiles\" --exclude \"progress\" --exclude \".bpipe\" --exclude \"rnaseq_pipeline.bpipe\" --exclude \"bpipe.config\" --exclude \"bpipe\" --exclude \"commandlog.txt\" -azvP $output.dir/ $rsync_path/$pre >$rsync_path/${pre}_rsync_log.txt", "run_rsync"
  }
}





skippedProcess = {}


//// the following code construct the pipeline work flow ////




def readProcessingWorkflow = prepareRead                     
if(flag_trim_read || flag_transcript || flag_detectfusion){
  readProcessingWorkflow = segment { readProcessingWorkflow + mergeRead }
}
if(flag_trim_read){
  readProcessingWorkflow = segment {readProcessingWorkflow + trimRead + compressRead}
}



def starWorkFlow = skippedProcess
if(flag_star)
{
  starWorkFlow = runStar1P
  if(!flag_star_1p)
  {
    starWorkFlow = segment {starWorkFlow + runStar2PGG + runStar2P}
  }
  starWorkFlow = segment {starWorkFlow + runStarProcessing}
  def starMetricsWorkFlow = segment {addGroup + 
                                    [flag_cufflinks ? runCufflinks.using(current_aligner:"star") : skippedProcess,
                                     collectRNAseqMetrics.using(current_aligner:"star"), 
                                     collectAlignmentSummaryMetrics.using(current_aligner:"star")]}
  def starAnalysisWorkFlow = skippedProcess
  if(flag_htseq || flag_dexseq)
  {
    starAnalysisWorkFlow = segment {sortSamQueryName.using(current_aligner:"star") +
                                    [flag_htseq ? runHtseq.using(current_aligner:"star") : skippedProcess, 
                                     flag_dexseq ? runDexseq.using(current_aligner:"star") : skippedProcess] }
  }
  starWorkFlow = segment {starWorkFlow + [starMetricsWorkFlow, starAnalysisWorkFlow]}
}



def tophatWorkFlow = skippedProcess
if(flag_tophat)
{
  tophatWorkFlow = runTopHat
  def tophatMetricsWorkFlow = segment {reorderSam + 
                                      [flag_cufflinks ? runCufflinks.using(current_aligner:"tophat") : skippedProcess,
                                      collectRNAseqMetrics.using(current_aligner:"tophat"), 
                                      collectAlignmentSummaryMetrics.using(current_aligner:"tophat")]
  }
  def tophatAnalysisWorkFlow = skippedProcess
  if(flag_htseq || flag_dexseq)
  {
    tophatAnalysisWorkFlow = segment {sortSamQueryName.using(current_aligner:"tophat") +
                                    [flag_htseq ? runHtseq.using(current_aligner:"tophat") : skippedProcess, 
                                     flag_dexseq ? runDexseq.using(current_aligner:"tophat") : skippedProcess] }
  }
  tophatWorkFlow = segment {tophatWorkFlow + [tophatMetricsWorkFlow, tophatAnalysisWorkFlow]}
}



def fusionWorkFlow = skippedProcess
if(flag_detectfusion)
{
    fusionWorkFlow = [flag_fusion_chimerascan ? runChimeraScan : skippedProcess,
                      flag_fusion_star ? runStarFusion : skippedProcess,
                      flag_fusion_mapsplice ? runMapSplice : skippedProcess,
                      flag_fusion_defuse ? runDefuse : skippedProcess,
                      flag_fusion_fusioncatcher ? runFusionCatcher : skippedProcess]
    fusionWorkFlow = segment{ fusionWorkFlow + mergeFusion }            
}



def transcriptWorkFlow = skippedProcess
if(flag_kallisto || flag_rsem || flag_express)
{
    transcriptWorkFlow = [flag_kallisto ? runKallisto : skippedProcess,
                          flag_rsem ? segment { runRsem + runRsemPlot } : skippedProcess,
                          flag_express ? segment {runBowtie2 + runExpress} : skippedProcess]
}



def collectTrimReadMetricsWorkFlow = skippedProcess
if(flag_trim_read)
{
  collectTrimReadMetricsWorkFlow = mergeCutadaptMetrics
}



def collectStarMetricsWorkFlow = skippedProcess
if(flag_star)
{  // using() can only be used in run{} or segment{}
  collectStarMetricsWorkFlow = segment{[flag_htseq ? countMatrixHtseq.using(current_aligner:"star")  : skippedProcess,
                                        flag_dexseq ? countMatrixDexseq.using(current_aligner:"star")  : skippedProcess,
                                        mergeAlignmentSummary.using(current_aligner:"star"),
                                        mergeRNAseqMetrics.using(current_aligner:"star")]}
  if(flag_htseq)
  {
    collectStarMetricsWorkFlow = segment { collectStarMetricsWorkFlow + runDeseqStar }
  }
}




def collectTophatMetricsWorkFlow = skippedProcess
if(flag_tophat)
{  // using() can only be used in run{} or segment{}
  collectTophatMetricsWorkFlow = segment{[flag_htseq ? countMatrixHtseq.using(current_aligner:"tophat")  : skippedProcess,
                                  flag_dexseq ? countMatrixDexseq.using(current_aligner:"tophat")  : skippedProcess,
                                  mergeAlignmentSummary.using(current_aligner:"tophat"),
                                  mergeRNAseqMetrics.using(current_aligner:"tophat")]}
  if(flag_htseq)
  {
    collectTophatMetricsWorkFlow = segment { collectTophatMetricsWorkFlow + runDeseqTophat }
  }
}



def collectTranscriptMetricsWorkFlow = skippedProcess
if(flag_kallisto || flag_rsem)
{
  collectTranscriptMetricsWorkFlow = [flag_kallisto ? countMatrixKallisto : skippedProcess,
                                      flag_rsem ? countMatrixRsem : skippedProcess]
  collectTranscriptMetricsWorkFlow = segment { collectTranscriptMetricsWorkFlow + [flag_kallisto ? runDeseqKallisto : skippedProcess, flag_rsem ? runDeseqRsem : skippedProcess] }
}



run {

  loadSoftwareConfig + loadAnnotationConfig + parseMappingFile + sample_libs_run_path * [ linkRead ] + sample_internal_path * [ readProcessingWorkflow + [ starWorkFlow, tophatWorkFlow, transcriptWorkFlow, fusionWorkFlow ] ] + [ collectTrimReadMetricsWorkFlow, collectStarMetricsWorkFlow, collectTophatMetricsWorkFlow, collectTranscriptMetricsWorkFlow ] + runCleanup + runRsync

}

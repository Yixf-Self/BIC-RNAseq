import static java.lang.System.err
import java.util.zip.*;

// variables need to be set from command line
Bin=""
SOFTWARE_CONFIG_FILE=""
ANNOTATION_CONFIG_FILE=""
MAPPING_FILE=""
COMPARISON_FILE=""
KEY_FILE=""
species=""
htseq_stranded=""
picard_strand_specificity=""
pre=""

flag_trim_read=false   // default is don't trim
r1adaptor=""
r2adaptor=""
flag_aligner="star"    //default is star 2pass
flag_star_2p=true
flag_cufflinks=false
flag_htseq=false
flag_dexseq=false
flag_deseq=false
flag_no_replicates=false
flag_detectfusion=false
flag_fusion_chimerascan=false
flag_fusion_star=false
flag_fusion_mapsplice=false
flag_fusion_defuse=false
flag_fusion_fusioncatcher=false
flag_transcript=false
flag_lncrna=false
flag_sort_query_sam=(flag_htseq || flag_dexseq)


uID=System.getProperty("user.name")
def SOFTWARE_PATH = [:]
def ANNOTATION_PATH
def sample_libs_run_path = [:]
def sample_internal_path = [:]
def sample_type_map = [:]
def sample_fusion_output = [:]
def sample_crm_output = ""
def sample_asm_output = ""


debug = {
  println "Bin=$Bin"
  println "SOFTWARE_CONFIG_FILE=$SOFTWARE_CONFIG_FILE"
  println "ANNOTATION_CONFIG_FILE=$ANNOTATION_CONFIG_FILE"
  println "MAPPING_FILE=$MAPPING_FILE"
  println "COMPARISON_FILE=$COMPARISON_FILE"
  println "KEY_FILE=$KEY_FILE"
  println "species=$species"
  println "htseq_stranded=$htseq_stranded"
  println "picard_strand_specificity=$picard_strand_specificity"
  println "pre=$pre"
  println "flag_trim_read=$flag_trim_read"
  println "r1adaptor=$r1adaptor"
  println "r2adaptor=$r2adaptor"
  println "flag_aligner=$flag_aligner"
  println "flag_star_2p=$flag_star_2p"
  println "flag_cufflinks=$flag_cufflinks"
  println "flag_htseq=$flag_htseq"
  println "flag_dexseq=$flag_dexseq"
  println "flag_deseq=$flag_deseq"
  println "flag_no_replicates=$flag_no_replicates"
  println "flag_detectfusion=$flag_detectfusion"
  println "flag_fusion_chimerascan=$flag_fusion_chimerascan"
  println "flag_fusion_star=$flag_fusion_star"
  println "flag_fusion_mapsplice=$flag_fusion_mapsplice"
  println "flag_fusion_defuse=$flag_fusion_defuse"
  println "flag_fusion_fusioncatcher=$flag_fusion_fusioncatcher"
  println "flag_transcript=$flag_transcript"
  println "flag_lncrna=$flag_lncrna"
  println "flag_sort_query_sam=$flag_sort_query_sam"
  fail "debug"
}

loadSoftwareConfig = {
  println "INFO: Loading software config file $SOFTWARE_CONFIG_FILE"
  File softwareConfigFile = new File(SOFTWARE_CONFIG_FILE)
  if(!softwareConfigFile.exists() || softwareConfigFile.isDirectory()) { 
    fail "ERROR: Could not open software config file $SOFTWARE_CONFIG_FILE"
  }
  softwareConfigFile.eachLine { line ->
    if(line.trim()) {
      def data = line.split("\\s+")
      def check_path = new File(data[1])
      if(!check_path.exists())
      {
        fail "ERROR: Path in software config file does not exist: " + data[1]
      }
      SOFTWARE_PATH[data[0]] = data[1]
    }
  }
}


loadAnnotationConfig = {
  println "INFO: Loading annotation config file $ANNOTATION_CONFIG_FILE"
  ANNOTATION_PATH = new ConfigSlurper(species).parse(new File(ANNOTATION_CONFIG_FILE).toURL())
  ANNOTATION_PATH.keySet().each{ ANNOTATION_PATH[it] = ANNOTATION_PATH[it].replaceAll("BIN_DIRECTORY_TOBE_SUBSTITUTE", Bin)}
  if(flag_lncrna)
  {
    ANNOTATION_PATH.GTF = ANNOTATION_PATH.GTF_LNCRNA
    ANNOTATION_PATH.starDB = ANNOTATION_PATH.starDB_LNCRNA
  }
  if(flag_trim_read)
  {
    ANNOTATION_PATH.starDB = ANNOTATION_PATH.starDB_adaptor
  }
  if(species == "hg19")
  {
    ANNOTATION_PATH.STAR_FUSION_GENOME_LIB = SOFTWARE_PATH.STAR_FUSION + "/Hg19_CTAT_resource_lib"
  }
}


parseMappingFile = {
	println "INFO: Parsing mapping file $MAPPING_FILE"
  File mappingFile = new File(MAPPING_FILE)
  if(!mappingFile.exists() || mappingFile.isDirectory()) { 
    fail "ERROR: Could not open mapping file $MAPPING_FILE"
  }
  check_unique = [:]                               // sometimes in the mapping file, the lib, sample, and run id isn't a unique identifier
	mappingFile.eachLine { line ->
		if(line.trim()) {
			data = line.split('\t')
			library_id = data[0]
      sample_name = data[1]
      run_id = data[2]
      fastq_path = data[3]
      sample_type = data[4]

      if(sample_name ==~ /^\d+.*/)
      {
        sample_name = "s_" + sample_name
      }
      key_value = sample_name + "\t" + library_id + "\t" + run_id
      
      if(check_unique[key_value])                                   //make sure the value in check_unique won't be groovy-false, such as 0
      {
        run_id += "_" + check_unique[key_value]
        check_unique[key_value] ++
      }
      else
      {
        check_unique[key_value] = 1
      }
      new_key_value = sample_name + "******" + library_id + "******" + run_id  // *,-,_ are the only characters that won't give weird stage name for next step, BPIPE bug?
      sample_libs_run_path[new_key_value] = fastq_path
      
      if(sample_type != "PE" && sample_type != "SE")
      {
        fail "ERROR: unrecognized sample type $sample_type for sample $sample_name"
      }
      if(sample_type_map[sample_name] && (sample_type_map[sample_name] != sample_type))
      {
        fail "ERROR: Sample $sample_name contains both PE and SE reads in mapping file"
      }
      else
      {
        sample_type_map[sample_name] = sample_type
      }

      internal_path = "intFiles/" + sample_name + "/" + library_id + "/" + run_id
      if(sample_internal_path.containsKey(sample_name))
  		{
    		sample_internal_path.get(sample_name).push(internal_path)
  		}
  		else
  		{
   			sample_internal_path.put(sample_name, [internal_path])
  		}
    }
	}	
}


linkRead = {
	branch.data = branch.name.split('\\*\\*\\*\\*\\*\\*')
	branch.sample = branch.data[0]
	branch.libid = branch.data[1]
	branch.runid = branch.data[2]
	output.dir = "intFiles/$branch.sample/$branch.libid/$branch.runid/"
	produce("softlink.done") {
	  exec "ln -s -f $input/* $output.dir >$output.done", "link_read"
  }
}


prepareRead = {
	branch.sample = branch.name
  branch.type = sample_type_map[branch.sample]
  branch.internal_path_list = inputs
  branch.R1 = []
  branch.R2 = []
  branch.min_read_len_cutadapt = -1
  branch.min_read_len_star = -1
  for(internal_path in branch.internal_path_list){
    from(glob(internal_path + "/*_R1_*.fastq.gz")){
      def R1_list = inputs.gz
      for(R1_file in R1_list){
        branch.R1.add(R1_file)
        if(branch.type == "PE")
        {
          def R1_file_name = R1_file.replaceFirst(~/^.*\/([^\/]+)$/, '$1')
          def R2_file_name = R1_file_name.replaceFirst(~/^(.*)R1(.*)$/, '$1R2$2')
          def R2_file = internal_path + "/" + R2_file_name
          File R2_FH = new File(R2_file)
          if(!R2_FH.exists() || R2_FH.isDirectory()) { 
            fail "ERROR: Could not find R2 file $R2_file"
          }
          branch.R2.add(R2_file)
        }
        if(branch.min_read_len_cutadapt == -1)  //check read lenth
        {
          def R1_input = new GZIPInputStream(new FileInputStream(R1_file))
          def R1_reader = new BufferedReader(new InputStreamReader(R1_input))
          def R1_line = R1_reader.readLine()
          R1_line = R1_reader.readLine() // get second line
          branch.min_read_len_cutadapt =  R1_line.size().intdiv(2)
          branch.min_read_len_star = branch.min_read_len_cutadapt - 1
        }
      }
    }
  }
	branch.R1_space_list = branch.R1.join(" ")
	branch.R2_space_list = (branch.type == "PE") ? branch.R2.join(" ") : ""
  branch.R1_comma_list = branch.R1.join(",")
  branch.R2_comma_list = (branch.type == "PE") ? branch.R2.join(",") : ""
  sample_fusion_output[branch.sample] = ""
}


mergeRead = {
	output.dir = "intFiles/$branch.sample/"
  if(branch.type == "SE") {
	  produce(branch.sample + "_R1_ORI.fastq"){	
		  exec "zcat $branch.R1_space_list >$output.fastq", "merge_read"
    }
    branch.original_merge_read1 = output1.fastq
    branch.original_merge_read2 = ""
  }
  else if(branch.type == "PE"){
    produce(branch.sample + "_R1_ORI.fastq", branch.sample + "_R2_ORI.fastq"){ 
      exec "zcat $branch.R1_space_list >$output1.fastq", "merge_read"
      exec "zcat $branch.R2_space_list >$output2.fastq", "merge_read"
    }
    branch.original_merge_read1 = output1.fastq
    branch.original_merge_read2 = output2.fastq
  }
}

trimRead = {
    output.dir = "intFiles/$branch.sample/"
    if(branch.type == "SE") {
      produce(branch.sample + "_R1_CT.fastq"){ 
        exec "$SOFTWARE_PATH.PYTHON/python $SOFTWARE_PATH.CUTADAPT/cutadapt -f fastq -m $branch.min_read_len_cutadapt -a $r1adaptor -O 10 -o $output.fastq $input1.fastq >$output.dir/${branch.sample}_R1_CUTADAPT_STATS.txt >$output.dir/cutadapt_trim_se.log 2>&1", "trim_read" 
      }
    }
    else if(branch.type == "PE"){
      produce(branch.sample + "_R1_CT.fastq", branch.sample + "_R2_CT.fastq"){  
        exec "$SOFTWARE_PATH.PYTHON/python $SOFTWARE_PATH.CUTADAPT/cutadapt -f fastq -m $branch.min_read_len_cutadapt -a $r1adaptor -O 10 --paired-output $output.dir/${branch.sample}_R2_TEMP.fastq -o $output.dir/${branch.sample}_R1_TEMP.fastq $input1.fastq $input2.fastq >$output.dir/${branch.sample}_R1_CUTADAPT_STATS.txt >$output.dir/cutadapt_trim_pe1.log 2>&1", "trim_read" 
        
        exec "$SOFTWARE_PATH.PYTHON/python $SOFTWARE_PATH.CUTADAPT/cutadapt -f fastq -m $branch.min_read_len_cutadapt -a $r2adaptor -O 10 --paired-output $output1.fastq -o $output2.fastq $output.dir/${branch.sample}_R2_TEMP.fastq $output.dir/${branch.sample}_R1_TEMP.fastq >$output.dir/${branch.sample}_R2_CUTADAPT_STATS.txt >$output.dir/cutadapt_trim_pe2.log 2>&1", "trim_read"
      }
    }
}

compressRead = {
    output.dir = "intFiles/$branch.sample/"
    if(branch.type == "SE") {
	    produce(branch.sample + "_R1.fastq.gz"){
		    exec "gzip -c $input1.fastq >$output1.gz", "compress_read"
      }
      branch.R1_comma_list = output1.gz
    }
    else if(branch.type == "PE"){
      produce(branch.sample + "_R1.fastq.gz", branch.sample + "_R2.fastq.gz"){
        exec "gzip -c $input1.fastq >$output1.gz", "compress_read"
		    exec "gzip -c $input2.fastq >$output2.gz", "compress_read"
    }
		branch.R1_comma_list = output1.gz
		branch.R2_comma_list = output2.gz
	 }
}

runTopHat = {   // it doesn't matter if R2 list is empty
    output.dir = "intFiles/tophat2/$branch.sample/"
    produce("accepted_hits.bam"){
      exec "$SOFTWARE_PATH.TOPHAT/tophat2 -p 6 -r 70 --mate-std-dev 90 --GTF $ANNOTATION_PATH.GTF --transcriptome-index=$ANNOTATION_PATH.TRANS_INDEX -o $output.dir --rg-id ${branch.sample}_1 --rg-sample $branch.sample --rg-library ${branch.sample}_1 --rg-platform Illumina --rg-platform-unit ${branch.sample}_1 $ANNOTATION_PATH.BOWTIE2_INDEX $branch.R1_comma_list $branch.R2_comma_list >$output.dir/tophat.log 2>&1", "run_tophat"
    }
    branch.tophat_bam = output.bam
}

reorderSam = {
    output.dir = "alignments/tophat2/"
    produce(pre + "_" + branch.sample + ".bam"){
      exec "$SOFTWARE_PATH.JAVA/java -Xms256m -Xmx10g -XX:-UseGCOverheadLimit -Djava.io.tmpdir=/scratch/$uID -jar $SOFTWARE_PATH.PICARD/picard.jar ReorderSam I=$input.bam O=$output.bam REFERENCE=$ANNOTATION_PATH.REF_SEQ VALIDATION_STRINGENCY=LENIENT TMP_DIR=/scratch/$uID CREATE_INDEX=true >${output.bam}.log 2>&1", "reorder_sam"
    }
    branch.final_bam = output.bam
}

runStar1P = {   // it doesn't matter if R2 list is empty
    output.dir = "intFiles/$branch.sample/"
    produce(branch.sample + "_STAR_1PASS_Aligned.out.sam", branch.sample + "_STAR_1PASS_SJ.out.tab"){
    	exec "$SOFTWARE_PATH.STAR/STAR --genomeDir $ANNOTATION_PATH.starDB --readFilesIn $branch.R1_comma_list $branch.R2_comma_list --runThreadN 12 --outFileNamePrefix $output.dir/${branch.sample}_STAR_1PASS_ --outSAMstrandField intronMotif --outFilterIntronMotifs RemoveNoncanonicalUnannotated --outSAMattributes All --outSAMunmapped Within --readFilesCommand zcat >$output.dir/star1p.log 2>&1", "run_star_1p"
    }
}

runStar2PGG = {
    output.dir = "intFiles/$branch.sample/star2passGG"
    produce("SAindex"){
    	exec "$SOFTWARE_PATH.STAR/STAR --runMode genomeGenerate --outFileNamePrefix $output.dir/ --genomeDir $output.dir --genomeFastaFiles $ANNOTATION_PATH.REF_SEQ --sjdbFileChrStartEnd $input.tab --sjdbOverhang $branch.min_read_len_star --runThreadN 12 >$output.dir/star2pgg.log 2>&1", "run_star_2p_gg"
    }
    branch.star_2p_gg = output.dir
}

runStar2P = {   // it doesn't matter if R2 list is empty
    output.dir = "intFiles/$branch.sample"
    produce(branch.sample + "_STAR_2PASS_Aligned.out.sam", branch.sample + "_STAR_2PASS_SJ.out.tab"){
    	exec "$SOFTWARE_PATH.STAR/STAR --genomeDir $branch.star_2p_gg --readFilesIn $branch.R1_comma_list $branch.R2_comma_list --runThreadN 12 --outFileNamePrefix $output.dir/${branch.sample}_STAR_2PASS_ --outSAMstrandField intronMotif --outFilterIntronMotifs RemoveNoncanonicalUnannotated --outSAMattributes All --outSAMunmapped Within --readFilesCommand zcat >$output.dir/star2p.log 2>&1", "run_star_2p"
    }
}

runStarProcessing = {
    output.dir = "intFiles/$branch.sample"
    produce(input.sam.replaceFirst(~/^.*\/([^\/]+)$/, '$1') + "_filtered.sam"){
    	exec "$SOFTWARE_PATH.PERL/perl $Bin/starProcessing.pl $input.sam >$output.dir/star_processing.log 2>&1", "run_star_processing"
    }
}

addGroup = {
    output.dir = "alignments"
    produce(pre + "_" + branch.sample + ".bam"){
      exec "$SOFTWARE_PATH.JAVA/java -Xms256m -Xmx10g -XX:-UseGCOverheadLimit -Djava.io.tmpdir=/scratch/$uID -jar $SOFTWARE_PATH.PICARD/picard.jar AddOrReplaceReadGroups I=$input.sam O=$output.bam SORT_ORDER=coordinate VALIDATION_STRINGENCY=LENIENT TMP_DIR=/scratch/$uID CREATE_INDEX=true RGID=${branch.sample}_1 RGLB=_1 RGPL=Illumina RGPU=${branch.sample}_1 RGSM=$branch.sample >${output.bam}.log 2>&1", "add_group"
    }
    branch.final_bam = output.bam
}


runCufflinks = {
    if(flag_aligner == "star"){
      output.dir = "cufflinks/$branch.sample"
    }
    else if(flag_aligner == "tophat"){
      output.dir = "cufflinks/tophat2/$branch.sample"
    }
    else
    {
      fail "ERROR: unrecognized aligner parameter"
    }
    produce("transcripts.gtf"){
    	exec "$SOFTWARE_PATH.CUFFLINKS/cufflinks -q -p 12 --no-update-check -N -G $ANNOTATION_PATH.GTF -o $output.dir $branch.final_bam >$output.dir/cufflink.log 2>&1", "run_cufflinks"
    }
}


sortSamQueryName = {
    output.dir = "intFiles/$branch.sample"
    produce(branch.sample + "_queryname_sorted.sam"){
    	exec "$SOFTWARE_PATH.JAVA/java -Xms256m -Xmx48g -XX:-UseGCOverheadLimit -Djava.io.tmpdir=/scratch/$uID -jar $SOFTWARE_PATH.PICARD/picard.jar MergeSamFiles INPUT=$branch.final_bam OUTPUT=$output.sam SORT_ORDER=queryname TMP_DIR=/scratch/$uID VALIDATION_STRINGENCY=LENIENT >$output.dir/sort_sam_queryname.log 2>&1", "sort_sam_query_name"
    }
    branch.query_name_sorted_sam = output.sam
}


runHtseq = {
    output.dir = "counts_gene"
    produce(branch.sample + ".htseq_count"){
    	exec "$SOFTWARE_PATH.PYTHON/python $SOFTWARE_PATH.HTSEQ/htseq-count -m intersection-strict -s $htseq_stranded -t exon $branch.query_name_sorted_sam $ANNOTATION_PATH.GTF >$output.htseq_count 2>${output.htseq_count}.log", "run_htseq"
    }
}

runDexseq = {
    output.dir = "counts_exon"
    produce(branch.sample + ".dexseq_count"){
    	exec "$SOFTWARE_PATH.PYTHON/python $SOFTWARE_PATH.DEXSEQ/dexseq_count.py -s no $ANNOTATION_PATH.DEXSEQ_GTF $branch.query_name_sorted_sam $output.dexseq_count >${output.dexseq_count}.log 2>&1", "run_dexseq"
    }
}


collectRNAseqMetrics = {
    output.dir = "metrics"
    produce(pre + "_" + branch.sample + "_CollectRnaSeqMetrics.txt", pre + "_" + branch.sample + "_CollectRnaSeqMetrics_chart.pdf"){
    	exec "$SOFTWARE_PATH.JAVA/java -Xms256m -Xmx3g -XX:-UseGCOverheadLimit -Djava.io.tmpdir=/scratch/$uID -jar $SOFTWARE_PATH.PICARD/picard.jar CollectRnaSeqMetrics I=$branch.final_bam O=$output1.txt CHART_OUTPUT=$output2.pdf REF_FLAT=$ANNOTATION_PATH.REF_FLAT RIBOSOMAL_INTERVALS=$ANNOTATION_PATH.RIBOSOMAL_INTERVALS STRAND_SPECIFICITY=$picard_strand_specificity METRIC_ACCUMULATION_LEVEL=null METRIC_ACCUMULATION_LEVEL=SAMPLE >${output1.txt}.log 2>&1", "collect_rnaseq_metrics"
    }
    sample_crm_output += " -metrics $output.txt"
}

collectAlignmentSummaryMetrics = {
    output.dir = "metrics"
    produce(pre + "_" + branch.sample + "_AlignmentSummaryMetrics.txt"){
    	exec "$SOFTWARE_PATH.JAVA/java -Djava.io.tmpdir=/scratch/$uID -jar $SOFTWARE_PATH.PICARD/picard.jar CollectAlignmentSummaryMetrics INPUT=$branch.final_bam OUTPUT=$output.txt REFERENCE_SEQUENCE=$ANNOTATION_PATH.REF_SEQ METRIC_ACCUMULATION_LEVEL=null METRIC_ACCUMULATION_LEVEL=SAMPLE VALIDATION_STRINGENCY=LENIENT >${output1.txt}.log 2>&1", "collect_alignment_summary_metrics"
    }
    sample_asm_output += " -metrics $output.txt"
}

runChimeraScan = {    // chimerascan does not support single end read
    output.dir = "fusion/chimerascan/$branch.sample"
    if(branch.type == "PE")
    {
      produce("chimeras.bedpe")
      {
        exec "$SOFTWARE_PATH.PYTHON/python $SOFTWARE_PATH.CHIMERASCAN/chimerascan_run.py --bowtie-path=$SOFTWARE_PATH.BOWTIE -p 6 --quals solexa --multihits=10 --filter-false-pos=$Bin/data/hg19_bodymap_false_positive_chimeras.txt $ANNOTATION_PATH.CHIMERASCAN_INDEX $branch.original_merge_read1 $branch.original_merge_read2 $output.dir >$output.dir/chimerascan.log 2>&1", "run_chimerascan"
      }
      sample_fusion_output[branch.sample] += " --chimerascan $output.bedpe"
    }
}

runStarFusion = {   // it doesn't matter if R2 list is empty
    output.dir = "fusion/star/$branch.sample"
    def read_para = "--left_fq $branch.original_merge_read1"
    if(branch.type == "PE")
    {
      read_para += " --right_fq $branch.original_merge_read2"
    }
    produce("star-fusion.fusion_candidates.final.abridged")
    {
      exec "$SOFTWARE_PATH.PERL/perl $SOFTWARE_PATH.STAR_FUSION/STAR-Fusion --genome_lib_dir $ANNOTATION_PATH.STAR_FUSION_GENOME_LIB $read_para --output_dir $output.dir >$output.dir/star_fusion.log 2>&1", "run_star_fusion"
    }
    sample_fusion_output[branch.sample] += " --star $output.abridged"
}

runMapSplice = {
    output.dir = "fusion/mapsplice/$branch.sample"
    def read_para = "-1 $branch.original_merge_read1"
    if(branch.type == "PE")
    {
      read_para += " -2 $branch.original_merge_read2"
    }
    produce("fusions_well_annotated.txt")
    {
      exec "$SOFTWARE_PATH.PYTHON/python $SOFTWARE_PATH.MAPSPLICE/mapsplice.py -p 6 --bam --fusion-non-canonical -c $ANNOTATION_PATH.chrSplits -x $ANNOTATION_PATH.BOWTIE_INDEX -o $output.dir $read_para --gene-gtf $ANNOTATION_PATH.GTF >$output.dir/mapsplice.log 2>&1", "run_mapsplice"
    }
    sample_fusion_output[branch.sample] += " --mapsplice $output.txt"
}

runDefuse = {
    output.dir = "fusion/defuse/$branch.sample"
    if(branch.type == "PE")
    {
      produce("results.filtered.tsv")
      {
        exec "$SOFTWARE_PATH.PERL/perl $SOFTWARE_PATH.DEFUSE/scripts/defuse.pl --config $SOFTWARE_PATH.DEFUSE/scripts/config_homo_sapiens.txt --output $output.dir --parallel 12 --1fastq ${branch.original_merge_read1} --2fastq ${branch.original_merge_read2} >$output.dir/defuse.log 2>&1", "run_defuse"
      }
      sample_fusion_output[branch.sample] += " --defuse $output.tsv"
    }
}

runFusionCatcher = {
    output.dir = "fusion/fusioncatcher/$branch.sample"
    if(branch.type == "PE")
    {
      produce("final-list_candidate-fusion-genes.txt")
      {
        exec "$SOFTWARE_PATH.FUSIONCATCHER/bin/fusioncatcher -d $SOFTWARE_PATH.FUSIONCATCHER/data/ensembl_v77d -i ${branch.original_merge_read1},${branch.original_merge_read2} -o $output.dir -p 6 --skip-update-check --config=$SOFTWARE_PATH.FUSIONCATCHER/bin/configuration.cfg >$output.dir/fusioncatcher.log 2>&1", "run_fusioncatcher"
      }
      sample_fusion_output[branch.sample] += " --fusioncatcher $output.txt"
    }
}

mergeFusion = {
  output.dir = "fusion"
  branch.merge_fusion = sample_fusion_output[branch.sample]
  produce(pre + "_merged_fusions_" + branch.sample + ".txt"){
    exec "$Bin/MergeFusion $branch.merge_fusion --out $output.txt --normalize_gene $Bin/data/hugo_data_073013.tsv", "merge_fusion"
  }
}

runBowtie2 = {
  output.dir = "intFiles/bowtie2/$branch.sample/"
  def read_para = ""
  if(branch.type == "PE")
  {
    read_para = "-1 $branch.original_merge_read1 -2 $branch.original_merge_read2"
  }
  else
  {
      read_para = "-U $branch.original_merge_read1"
  }
  produce(branch.sample + "_bowtie2.sam"){
  exec "$SOFTWARE_PATH.BOWTIE2/bowtie2 --all --maxins 600 --rdg 6,5 --rfg 6,5 --score-min L,-.6,-.4 --no-discordant --no-mixed --threads 24 -x $ANNOTATION_PATH.TRANS_INDEX_DEDUP $read_para -S $output.sam >$output.dir/bowtie2.log 2>&1", "run_bowtie2"
  branch.bowtie2_sam = output.sam
  }
}

runExpress = {
  output.dir = "transcript/express/$branch.sample"
  produce("results.xprs") {
    exec "$SOFTWARE_PATH.EXPRESS/express --output-dir $output.dir --no-update-check $ANNOTATION_PATH.TRANS_FASTA_DEDUP $branch.bowtie2_sam >$output.dir/express.log 2>&1", "run_express"
  }
}


runKallisto = {     // it doesn't matter if R2 list is empty
  output.dir = "transcript/kallisto/$branch.sample"
  def read_para = ""
  if(branch.type == "PE")
  {
      produce("abundance.txt") {
        exec "$SOFTWARE_PATH.KALLISTO/kallisto quant -i $ANNOTATION_PATH.KALLISTO_INDEX -o $output.dir -b 100 $read_para $branch.original_merge_read1 $branch.original_merge_read2 >$output.dir/kallisto.log 2>&1", "run_kallisto"
    }
  }
}


countMatrixHtseq = {
  output.dir = "counts_gene"
  produce(pre + "_htseq_all_samples.txt") {
    exec "$SOFTWARE_PATH.PYTHON/python $Bin/rnaseq_count_matrix.py $output.dir .htseq_count $output.txt $ANNOTATION_PATH.geneNameConversion >${output.txt}.log 2>&1", "count_matrix_htseq"
  }
}


countMatrixDexseq = {
  output.dir = "counts_exon"
  produce(pre + "_dexseq_all_samples.txt") {
    exec "$SOFTWARE_PATH.PYTHON/python $Bin/rnaseq_count_matrix.py $output.dir .dexseq_count $output.txt $ANNOTATION_PATH.geneNameConversion >${output.txt}.log 2>&1", "count_matrix_dexseq"
  }
} 


mergeAlignmentSummary = {
  output.dir = "metrics"
  produce(pre + "_AlignmentSummaryMetrics.txt") {
    exec "$SOFTWARE_PATH.PERL/perl $Bin/mergePicardMetrics.pl $sample_asm_output >$output.txt 2>${output.txt}.log", "merge_alignment_summary"
  } 

}


mergeRNAseqMetrics = {
    output.dir = "metrics"
    produce(pre + "_CollectRnaSeqMetrics.txt") {
    exec "$SOFTWARE_PATH.PERL/perl $Bin/mergePicardMetrics.pl $sample_crm_output >$output.txt 2>${output.txt}.log", "merge_rnaseq_metrics"
  }
}


mergeCutadaptMetrics = {
  output.dir = "metrics"
  produce(pre + "_CutAdaptStats.txt") {
    exec "$SOFTWARE_PATH.PYTHON/python $Bin/mergeCutAdaptStats.py ./intFiles/ '*CUTADAPT_STATS.txt' $output.txt >${output.txt}.log 2>&1", "merge_cutadapt_metrics"
  }
}


runDeseq = {
  def root_dir = output.dir
  output.dir = "gsa"
  output.dir = "differentialExpression_gene"
  output.dir = "clustering"
  produce("MDS_plot.pdf", "counts_DESeqscaled_clust.pdf"){
  def extra_para = "";
  if(flag_deseq)
  {
    extra_para += "-pre $pre -diff_out $root_dir/differentialExpression_gene -count_out $root_dir/counts_gene -gsa_out $root_dir/gsa -species $species -samplekey $KEY_FILE -comparisons $COMPARISON_FILE"
    if(flag_aligner == "star" && flag_no_replicates)
    {
      extra_para += " -no_replicates"
    }
  }
  else
  {
    extra_para += " -clusterOnly"
  }
  exec "$SOFTWARE_PATH.PERL/perl $Bin/run_DESeq_wrapper.pl -cluster_out $output.dir -config $SOFTWARE_CONFIG_FILE -bin $Bin -counts $root_dir/counts_gene/${pre}_htseq_all_samples.txt $extra_para >$output.dir/deseq.log 2>&1", "run_deseq"
  }
}


skippedProcess = {}








//// the following code construct the pipeline work flow ////


//// read processing work flow ////
def readProcessingWorkflow = prepareRead                     
if(flag_trim_read || flag_detectfusion){
  readProcessingWorkflow = segment { readProcessingWorkflow + mergeRead }
}
if(flag_trim_read){
  readProcessingWorkflow = segment {readProcessingWorkflow + trimRead + compressRead}
}


//// alignment work flow ////
def alignmentWorkflow
if(flag_aligner=="tophat"){
  alignmentWorkflow = segment {runTopHat + reorderSam}
}
else if(flag_aligner=="star"){
  alignmentWorkflow = runStar1P
  if(flag_star_2p)
  {
    alignmentWorkflow = segment {alignmentWorkflow + runStar2PGG + runStar2P}
  }
  alignmentWorkflow = segment {alignmentWorkflow + runStarProcessing + addGroup}
}
else{
	err.println "ERROR: Unrecognized aligner specified"
	System.exit(1)
}


//// analysis work flow ////
def seqAnalysisWorkflow = segment {((flag_htseq || flag_dexseq) ? sortSamQueryName : skippedProcess) +
                                  [flag_htseq ? runHtseq : skippedProcess, 
                                   flag_dexseq ? runDexseq : skippedProcess] }



//// cufflinks work flow ////
def cufflinksWorkflow = flag_cufflinks ? runCufflinks : skippedProcess


//// metrics work flow ////
def metricsWorkflow = [collectRNAseqMetrics, collectAlignmentSummaryMetrics]


//// fusion work flow ////
def fusionWorkFlow = skippedProcess
if(flag_detectfusion)
{
    fusionWorkFlow = [flag_fusion_chimerascan ? runChimeraScan : skippedProcess,
                      flag_fusion_star ? runStarFusion : skippedProcess,
                      flag_fusion_mapsplice ? runMapSplice : skippedProcess,
                      flag_fusion_defuse ? runDefuse : skippedProcess,
                      flag_fusion_fusioncatcher ? runFusionCatcher : skippedProcess]
    fusionWorkFlow = segment{ fusionWorkFlow + mergeFusion }            
}


//// transcript work flow ////
def transcriptWorkFlow = skippedProcess
if(flag_transcript)
{
    transcriptWorkFlow = segment{runBowtie2 + runExpress + runKallisto}
}


//// collect metrics work flow ////
def collectMetricsWorkFlow
collectMetricsWorkFlow = [flag_htseq ? countMatrixHtseq : skippedProcess,
                          flag_dexseq ? countMatrixDexseq : skippedProcess,
                          mergeAlignmentSummary,
                          mergeRNAseqMetrics,
                          flag_trim_read ? mergeCutadaptMetrics : skippedProcess]
collectMetricsWorkFlow = segment { collectMetricsWorkFlow + runDeseq }




run {
   loadSoftwareConfig + loadAnnotationConfig + parseMappingFile + sample_libs_run_path * [ linkRead ] + sample_internal_path * [ readProcessingWorkflow + alignmentWorkflow + [ seqAnalysisWorkflow, cufflinksWorkflow, metricsWorkflow, fusionWorkFlow, transcriptWorkFlow] ] + collectMetricsWorkFlow 
}
